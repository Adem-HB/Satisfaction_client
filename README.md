# NLP Project â€” Analyse de sentiment dâ€™avis Trustpilot (Cdiscount)

## ğŸ¯ Objectif du projet

Construire une **chaÃ®ne complÃ¨te de traitement NLP** (de la collecte Ã  lâ€™Ã©valuation) pour **classer automatiquement le sentiment** dâ€™avis clients (positif / nÃ©gatif) Ã  partir de commentaires textuels.

Dans ce notebook, le cas dâ€™usage est : **avis Trustpilot de Cdiscount**.

Objectifs opÃ©rationnels :
- **Collecter** des avis (commentaires + notes) depuis Trustpilot.
- **Nettoyer** et normaliser le texte.
- **PrÃ©traiter NLP** (lemmatisation FR) et reprÃ©senter les textes (TF-IDF).
- **Ã‰valuer** des modÃ¨les de sentiment **prÃ©-entraÃ®nÃ©s** (Transformers) sur plusieurs versions du texte.
- **Analyser les erreurs** (faux positifs / faux nÃ©gatifs) et mesurer lâ€™impact du nettoyage/lemmatisation.

---

## ğŸ§© Contenu du projet (ce qui existe aujourdâ€™hui)

Le projet est actuellement centrÃ© sur un notebook unique :

- `nlp_project.ipynb` : pipeline end-to-end (scraping â†’ nettoyage â†’ NLP â†’ benchmark modÃ¨les â†’ analyse dâ€™erreurs)

**Colonnes clÃ©s crÃ©Ã©es dans le notebook :**
- `comment` : avis brut rÃ©cupÃ©rÃ©
- `rating` : note (float)
- `label` : cible binaire dÃ©rivÃ©e de la note  
  - `1` si `rating >= 4` (positif)
  - `0` sinon (nÃ©gatif)
- `clean_comment` : texte nettoyÃ© (minuscules, ponctuation supprimÃ©e, chiffres/emoji/char spÃ©ciaux supprimÃ©sâ€¦)
- `lemmatized` : version lemmatisÃ©e via spaCy FR
- Colonnes de prÃ©diction (sur un Ã©chantillon) du type `pred_<model_name>` et variantes selon la version texte.

---

## ğŸ§  DonnÃ©es & Ã©tiquetage

### Source
- Trustpilot (page FR) : avis de `www.cdiscount.com` (scraping HTML)

### Labeling (supervision faible)
Le label est dÃ©rivÃ© de la note :
- **positif** si note â‰¥ 4
- **nÃ©gatif** sinon

> Remarque : câ€™est un proxy (faible supervision). Un 3â˜… peut Ãªtre â€œneutreâ€ mais est rangÃ© ici en nÃ©gatif.

---

## ğŸ” Pipeline actuel (dans le notebook)

### 1) Collecte (scraping)
- RequÃªtes `requests` vers Trustpilot avec `User-Agent`
- Extraction par expressions rÃ©guliÃ¨res :
  - `reviewBody` pour le texte
  - `ratingValue` pour la note
- Pagination : boucle sur `?page=...`

âš ï¸ **Attention** : Trustpilot peut limiter/bloquer le scraping. Utiliser des dÃ©lais, headers, et rester raisonnable.

### 2) Nettoyage structurel
- `dropna`, `drop_duplicates`, suppression des commentaires vides
- Construction de la cible `label`

### 3) Nettoyage texte (`clean_text`)
- suppression HTML (BeautifulSoup)
- lowercasing
- suppression ponctuation
- option : suppression chiffres
- suppression emojis / caractÃ¨res non-ASCII
- normalisation espaces

### 4) PrÃ©traitement NLP
- tÃ©lÃ©chargement du modÃ¨le spaCy FR : `fr_core_news_sm`
- lemmatisation + suppression stopwords + tokens alpha

### 5) Vectorisation (baseline â€œclassiqueâ€)
- `TfidfVectorizer(max_features=5000)`

### 6) Split & gestion dÃ©sÃ©quilibre
- `train_test_split(..., stratify=y)`
- calcul des `class_weight` (utile si entraÃ®nement dâ€™un modÃ¨le supervisÃ©)

### 7) Benchmark Transformers (prÃ©-entraÃ®nÃ©s)
Test sur un **sous-Ã©chantillon** (100 avis) via `transformers.pipeline` :
- `tblard/tf-allocine`
- `nlptown/bert-base-multilingual-uncased-sentiment`
- `cardiffnlp/twitter-xlm-roberta-base-sentiment`

Ã‰valuation :
- `classification_report` (precision/recall/f1)
- analyse des erreurs : faux positifs / faux nÃ©gatifs
- comparaison de lâ€™impact du **texte brut** vs **clean** vs **lemmatized** (selon le bloc).

---

## âœ… OÃ¹ tu en es maintenant (Ã©tat actuel)

Ã€ ce stade, le projet a dÃ©jÃ  :
- âœ… rÃ©cupÃ©rÃ© des avis Trustpilot (texte + note) via scraping
- âœ… construit un dataset et une cible binaire (Ã  partir de la note)
- âœ… implÃ©mentÃ© un nettoyage robuste du texte
- âœ… ajoutÃ© une lemmatisation FR (spaCy)
- âœ… vectorisÃ© en TF-IDF (prÃ©paration pour modÃ¨les ML â€œclassiquesâ€)
- âœ… benchmarkÃ© plusieurs modÃ¨les Transformers prÃ©-entraÃ®nÃ©s
- âœ… lancÃ© une analyse dâ€™erreurs (FP/FN) et lâ€™impact du nettoyage

Ce qui **nâ€™est pas encore rÃ©ellement finalisÃ©** (prochaines Ã©tapes naturelles) :
- â³ entraÃ®ner un modÃ¨le supervisÃ© (LogReg/SVM) sur TF-IDF
- â³ fine-tuner un modÃ¨le FR (CamemBERT/FlauBERT) sur tes labels
- â³ fiabiliser le scraping (gestion anti-bot, backoff, stockage incrÃ©mental)
- â³ persister les donnÃ©es (`.csv`/`.parquet`) et versionner les jeux de donnÃ©es
- â³ ajouter une vraie â€œclasse neutreâ€ (ou regression sur la note 1â€“5)

---

## âš™ï¸ PrÃ©requis

### Environnement
- Python 3.9+ recommandÃ©
- Jupyter Notebook / JupyterLab

### DÃ©pendances principales
- `requests`
- `beautifulsoup4`
- `pandas`, `numpy`
- `scikit-learn`
- `matplotlib` (et Ã©ventuellement `seaborn`)
- `transformers`
- `torch`
- `spacy` + modÃ¨le `fr_core_news_sm`

Installation typique :
```bash
pip install -U requests beautifulsoup4 pandas numpy scikit-learn matplotlib seaborn transformers torch spacy
python -m spacy download fr_core_news_sm
```

> Si tu es sur Apple Silicon / CUDA / environnements spÃ©cifiques, adapte lâ€™installation de `torch` selon ta plateforme.

---

## â–¶ï¸ ExÃ©cution

1. Ouvrir le notebook :
   - `nlp_project.ipynb`
2. ExÃ©cuter les cellules dans lâ€™ordre :
   - Scraping â†’ Nettoyage â†’ Lemmatisation â†’ Benchmark modÃ¨les
3. Ajuster si besoin :
   - `base_url`
   - le nombre de pages (boucle de pagination)
   - la taille de lâ€™Ã©chantillon `sample_df = df.sample(...)`

---

## ğŸ“Œ Bonnes pratiques & remarques

- **Respect des CGU** : le scraping peut Ãªtre restreint par Trustpilot. Limiter le volume, ajouter des pauses, et envisager des sources alternatives/datasets publics si nÃ©cessaire.
- **Regex fragiles** : les patterns dâ€™extraction peuvent casser si la structure HTML/JSON embarquÃ© change.
- **Labels bruitÃ©s** : la note nâ€™est pas un sentiment parfait, surtout pour 3â˜….

---

## ğŸ—ºï¸ Roadmap (suggestion)

1. **Baseline supervisÃ©e** : Logistic Regression / Linear SVM sur TF-IDF + class_weight  
2. **Meilleure Ã©valuation** : k-fold, courbe PR, matrice de confusion, calibration  
3. **Fine-tuning** : CamemBERT/FlauBERT sur dataset (aprÃ¨s nettoyage)  
4. **Industrialisation** :
   - extraction robuste (retry/backoff)
   - export dataset en `parquet`
   - pipeline reproductible (scripts + config)
   - suivi dâ€™expÃ©riences (MLflow)

---

## ğŸ§‘â€ğŸ’» Auteur

Adem

